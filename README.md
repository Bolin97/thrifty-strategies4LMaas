# thrifty-strategies4LMaas
Paper list for the survey: Low-Latency, High-quality, and Cost-Saving Strategies for the Invocation of Massive LLM API Services

Labels: `publisher year` ðŸ“„[PDF](), ðŸ”—[Codes](), ðŸ’¡[Demo]()

## Input Abstraction
### Sentence Simplification
#### Methods
TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. `EMNLP (Findings) 2023`  ðŸ“„[PDF](https://aclanthology.org/2023.findings-emnlp.655.pdf)

Learned Token Pruning for Transformers. `KDD 2022` ðŸ“„[PDF](https://dl.acm.org/doi/10.1145/3534678.3539260)

Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing. ðŸ“„[PDF](https://arxiv.org/pdf/2308.03558.pdf)
#### Surveys
The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey. ðŸ“„[PDF](https://arxiv.org/pdf/2104.14839.pdf)

A Comparative Survey of Text Summarization Techniques. `SN Computer Science 2024`  ðŸ“„[PDF](https://link.springer.com/article/10.1007/s42979-023-02343-6)

### Prompt Optimization

## Semantic Cache
### Traditional Cache

### Neural Cache



## Solution Creation
### Scoring Function
### LLM Router

## Output Optimization
